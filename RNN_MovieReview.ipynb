{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d47e9aeb",
   "metadata": {},
   "source": [
    "# Using RNNs for movie reviews\n",
    "\n",
    "Keras has a imdb_lstm.py example of using RNNs. The data set consists of user-generated movie reviews and classification of whether the user liked the movie or not based.\n",
    "\n",
    "More info on the dataset is here:\n",
    "https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification\n",
    "\n",
    "The objective is to use a RNN to do sentiment analysis on full-text movie reviews. An artificial neural network will be trained to read movie reviews and guess whether the author liked the movie or not.\n",
    "\n",
    "The understanding of written language requires keeping track of all the words in a sentence, a RNN is necessary to keep \"memory\" of the words that have come before as it \"reads\" sentences over time. In particular, LSTM (Long Short-Term Memory) will be used because the netowork shouldn't \"forget\" words too quickly - words early on in a sentence can affect the meaning of that sentence significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68a7aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d05a2e",
   "metadata": {},
   "source": [
    "# Import training and test data\n",
    "\n",
    "Define that only 20,000 most popular words in the dataset will be used. \n",
    "- Each word should be transformed to a number in order to the RNN understand it. This is luckly already done.\n",
    "\n",
    "The dataset includes 5,000 training reviews and 25,000 testing reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e5e413",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb419c",
   "metadata": {},
   "source": [
    "# How a movie review looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b1694d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce5466",
   "metadata": {},
   "source": [
    "# Pre processing\n",
    "\n",
    "That doesn't look like a movie review. This data set has spared a lot of trouble - they have already converted words to integer-based indices. The actual letters that make up a word don't really matter as far as the model is concerned, what matters are the words themselves - and the model needs numbers to work with, not letters.\n",
    "\n",
    "Each number in the training features represent some specific word. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a367ea7",
   "metadata": {},
   "source": [
    "# What do the labels look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34bb77c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417d589e",
   "metadata": {},
   "source": [
    "0 or 1, which indicates whether the reviewer said they liked the movie or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a92304",
   "metadata": {},
   "source": [
    "# Limiting the features\n",
    "\n",
    "RNNs can blow up quickly, so to keep things managable, let's limit the reviews to their first 80 words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85068760",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=80)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaacd89",
   "metadata": {},
   "source": [
    "# Setting up the RNN\n",
    "\n",
    "Considering how complicated a LSTM recurrent neural network is under the hood, it's really amazing how easy this is to do with Keras.\n",
    "\n",
    "1. An Embedding layer: a step that converts the input data into dense vectors of fixed size that's better suited for a neural network. It is generally used in conjunction with index-based text data like we have here. The 20000 indicates the vocabulary size and 128 is the output dimension of 128 units.\n",
    "\n",
    "2. Set up a LSTM layer for the RNN itself. Specify 128 to match the output size of the Embedding layer, and dropout terms to avoid overfitting, which RNN's are particularly prone to.\n",
    "\n",
    "3. Single neuron with a sigmoid activation function to choose binay sentiment classification of 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b33b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = Sequential()\n",
    "    model.add(Embedding(20000, 128))\n",
    "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f4e94d",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "\n",
    "Binary classification problem = inary_crossentropy loss function. And the Adam optimizer is usually a good choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07388a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb7503c",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "RNN's, like CNN's, are very resource heavy. Keeping the batch size relatively small is the key to enabling this to run. In the real word of course, you'd be taking advantage of GPU's installed across many computers on a cluster to make this scale a lot better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d5bf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "782/782 - 209s - loss: 0.4362 - accuracy: 0.7948 - val_loss: 0.3741 - val_accuracy: 0.8326\n",
      "Epoch 2/15\n",
      "782/782 - 200s - loss: 0.2607 - accuracy: 0.8963 - val_loss: 0.3742 - val_accuracy: 0.8401\n",
      "Epoch 3/15\n",
      "782/782 - 202s - loss: 0.1708 - accuracy: 0.9360 - val_loss: 0.4487 - val_accuracy: 0.8236\n",
      "Epoch 4/15\n",
      "782/782 - 200s - loss: 0.1127 - accuracy: 0.9582 - val_loss: 0.5914 - val_accuracy: 0.8196\n",
      "Epoch 5/15\n",
      "782/782 - 200s - loss: 0.0668 - accuracy: 0.9767 - val_loss: 0.6577 - val_accuracy: 0.8184\n",
      "Epoch 6/15\n",
      "782/782 - 205s - loss: 0.0507 - accuracy: 0.9835 - val_loss: 0.6496 - val_accuracy: 0.8084\n",
      "Epoch 7/15\n",
      "782/782 - 205s - loss: 0.0393 - accuracy: 0.9866 - val_loss: 0.7526 - val_accuracy: 0.8212\n",
      "Epoch 8/15\n",
      "782/782 - 199s - loss: 0.0298 - accuracy: 0.9904 - val_loss: 0.8798 - val_accuracy: 0.8174\n",
      "Epoch 9/15\n",
      "782/782 - 152s - loss: 0.0261 - accuracy: 0.9920 - val_loss: 0.8043 - val_accuracy: 0.8171\n",
      "Epoch 10/15\n",
      "782/782 - 149s - loss: 0.0175 - accuracy: 0.9945 - val_loss: 1.1897 - val_accuracy: 0.7917\n",
      "Epoch 11/15\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=15,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e3c770",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=32,\n",
    "                            verbose=2)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3344616d",
   "metadata": {},
   "source": [
    "80% eh? Not too bad, considering that it was limited to just the first 80 words of each review.\n",
    "\n",
    "Note that the validation accuracy while we were training never really improved after the first epoch; it is likely just overfitting. This is a case where early stopping would have been beneficial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7864e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
