{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hands on in the Tensorflow playground\n",
    "\n",
    "This lesson is based in the [tensorflow playground](http://playground.tensorflow.org/). Some exercises are developed here and there is no code, but the images and explanation of what I did in this lesson are presented.\n",
    "\n",
    "The tensorflow playground allows you to literally play around with some deep learning stuff. It has 4 different datasets and an interface to choose a handful of the neural network parameters. The image presents the site homepage when you first acess it. Here we can see the dataset to be used, the interactive neural net, where you can choose the amount of layers and neurons in each layer, the output result, and others neural network parameters.\n",
    "\n",
    "Once you setup your neural network, you can press the play button and it will start training. As the epochs go on, the output graphic is updated to fit the background colour accordingly to the samples classes (orange or blue). At the end of the page, the site has an explanation about neural networks, disclaimer about license and the credits.\n",
    "\n",
    "<img src=\"course_imgs/tensorflowplayground.png\" alt=\"Tensorflow playground\" width=\"500\"/>\n",
    "\n",
    " ## First dataset experimentation\n",
    " \n",
    " ##### First try\n",
    " \n",
    "The first experiment was realized with the setup provided by the page. As the start button was pressed, the output converged to the result shown in the image. As it is possible to see, the result was really satisfactory after only 50 epochs.\n",
    " \n",
    " <img src=\"course_imgs/playground_1.png\" alt=\"First playground attempt\" width=\"500\"/>\n",
    " \n",
    " ##### Second try\n",
    " \n",
    "Since the first try was clearly a overkill, the neural network size was reduced. By removing one neuron of the second layer, the result was still reached very fast. Because of that, I removed the whole second layer, and let 1 layer with 4 neurons. The result was still very fast. So, the neurons # was reduced to 3. The image shows the result. After 150 epochs, a satisfactory result was achieved. \n",
    " \n",
    "<img src=\"course_imgs/playground_2.png\" alt=\"Second playground attempt\" width=\"500\"/>\n",
    "\n",
    "However, if the second layer is reduced to 2 neurons, the neural network won't have a good performance, as shown in the image. This is the limit for the dataset.\n",
    "\n",
    "<img src=\"course_imgs/playground_3.png\" alt=\"Third playground attempt\" width=\"500\"/>\n",
    "\n",
    "## Second dataset experimentation\n",
    "\n",
    "The lesson continues to the second dataset, and I reset the neural network to the standard version with the spiral dataset, as in the image.\n",
    "\n",
    "<img src=\"course_imgs/playground_4.png\" alt=\"Second dataset\" width=\"500\"/>\n",
    "\n",
    "By running the neural network, after 1000 epochs it was not possible to obtain a satisfactory result, as seen in the image, meaning that it is necessary to increases the network size.\n",
    "\n",
    "<img src=\"course_imgs/playground_5.png\" alt=\"Second dataset\" width=\"500\"/>\n",
    "\n",
    "After several attempts, the Neural Network was defined as in the image. Because of the network size, the epochs became very slow, but eventually, for a hard dataset to classify as the used, a satisfying result was obtained. \n",
    "\n",
    "<img src=\"course_imgs/playground_6.png\" alt=\"Second dataset\" width=\"500\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
